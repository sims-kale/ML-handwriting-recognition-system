{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2630323060.py, line 21)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mclahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(10, 10)):\u001b[39m\n                                                                 ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_digits = []  # List to store digits for each image\n",
    "dataset_path = r'D:\\SHU\\ML_lab\\Assesment\\Number_Test_Data'\n",
    "all_images = [img for img in os.listdir(dataset_path) if img.endswith(\".png\")]\n",
    "image_path = [os.path.join(dataset_path, img_path) for img_path in all_images[13:14]]\n",
    "print(image_path)\n",
    "for img_path in image_path:\n",
    "    print(f\"Processing image: {img_path}\")\n",
    "    raw_image = cv2.imread(img_path)  # Access each image in the list\n",
    "    if raw_image is None:\n",
    "        print(\"Error: Image not found or unable to open.\")\n",
    "    else:\n",
    "        resized_image = cv2.resize(raw_image, (580, 580), interpolation=cv2.INTER_AREA)\n",
    "        cv2.imshow(\"Image\", resized_image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Convert to grayscale\n",
    "gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply CLAHE for contrast enhancement\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(10, 10))\n",
    "enhanced_image = clahe.apply(gray_image)\n",
    "cv2.imshow(\"Enhanced Image\", enhanced_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Apply adaptive thresholding to create a binary image\n",
    "_, thresholded_image = cv2.threshold(enhanced_image, 85, 225, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow(\"Thresholded Image\", thresholded_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# thresholded_image = cv2.adaptiveThreshold(\n",
    "#     enhanced_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "#     cv2.THRESH_BINARY_INV, 25, 12\n",
    "# )\n",
    "# cv2.imshow(\"Thresholded Image\", thresholded_image)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# Detect and remove lines using Hough Line Transform\n",
    "lines = cv2.HoughLinesP(thresholded_image, 1, np.pi / 180, 100, minLineLength=30, maxLineGap=19.5)\n",
    "if lines is not None:\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(thresholded_image, (x1, y1), (x2, y2), (0,0,0),2)\n",
    "cv2.imshow(\"Lines Removed\", thresholded_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# line_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40,1 ))\n",
    "# detected_lines = cv2.morphologyEx(thresholded_image, cv2.MORPH_OPEN, line_kernel, iterations=1)\n",
    "# cnts_lines, _ = cv2.findContours(detected_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# for c in cnts_lines:\n",
    "#     cv2.drawContours(thresholded_image, [c], -1, (0, 0, 0), thickness=cv2.FILLED)\n",
    "    # Optional: Apply a slight erosion to separate merged digits\n",
    "# kernel_small = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "# thresholded_image = cv2.erode(thresholded_image, kernel_small, iterations=1)\n",
    "# cv2.imshow(\"Eroded Image\", thresholded_image)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# Debug: Visualize contours\n",
    "contours, _ = cv2.findContours(thresholded_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "debug_image = cv2.cvtColor(thresholded_image.copy(), cv2.COLOR_GRAY2BGR)\n",
    "bounding_boxes = []\n",
    "for c in contours:\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    area = cv2.contourArea(c)\n",
    "    # Filter out too-small or too-large bounding boxes\n",
    "    if w < 3 or h < 10 or w > 200 or h > 200:\n",
    "        continue\n",
    "    bounding_boxes.append((x, y, w, h))\n",
    "    cv2.rectangle(debug_image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "cv2.imshow(\"Bounding Boxes\", debug_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# Sort by y first (for multiple rows) then x (for left-to-right)\n",
    "bounding_boxes = sorted(bounding_boxes, key=lambda b: (b[1], b[0]))\n",
    "digit_images = []\n",
    "for x, y, w, h in bounding_boxes:\n",
    "    digit_roi = thresholded_image[y:y+h, x:x+w]\n",
    "    digit_images.append(digit_roi)\n",
    "all_digits.append(digit_images)\n",
    "\n",
    "# Display digits for this image\n",
    "plt.figure(figsize=(10, 2))\n",
    "for i, digit_image in enumerate(digit_images):\n",
    "    plt.subplot(1, len(digit_images), i+1)\n",
    "    plt.imshow(digit_image, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(dataset_path):\n",
    "\n",
    "    # \".AVI\" VIDEO PRE_PROCESSING\n",
    "    try:\n",
    "        for video_path in os.listdir(dataset_path):\n",
    "            video = os.path.join(dataset_path, video_path)\n",
    "            video_op_path = os.path.join(dataset_path, \"video_frames\")\n",
    "            if not os.path.exists(video_op_path):\n",
    "                os.makedirs(video_op_path)\n",
    "            if video_path.endswith(\".avi\"):\n",
    "                # print(video)\n",
    "                videoCap = cv2.VideoCapture(video)  # Read the video\n",
    "                frameCount = 0\n",
    "                while videoCap.isOpened():\n",
    "                    reading, frame = videoCap.read()\n",
    "                    if not reading:\n",
    "                        break  # stop if the video finish\n",
    "                    grayscale_frames = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                    resize_frames = cv2.resize(grayscale_frames, (255, 255))\n",
    "                    # Apply Gaussian Blur\n",
    "                    blurred_frame = cv2.GaussianBlur(resize_frames, (1, 1), 0)\n",
    "                    _, binarized_frame = cv2.threshold(\n",
    "                        blurred_frame, 170, 255, cv2.THRESH_BINARY_INV\n",
    "                    )\n",
    "                    filename = f\"frame_{frameCount}.png\"\n",
    "                    path = os.path.join(video_op_path, filename)\n",
    "                    if frameCount % 10 == 0:\n",
    "                        cv2.imwrite(path, binarized_frame)\n",
    "                    # print(video_op_path,filename)\n",
    "                    frameCount += 1\n",
    "                    cv2.waitKey(10)\n",
    "                videoCap.release()\n",
    "                # cv2.destroyAllWindows()\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred in image preprocessing: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
